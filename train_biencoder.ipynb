{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install faiss-gpu-cu12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import CrossEncoder, InputExample, SentenceTransformer, losses\n",
    "from sentence_transformers.cross_encoder.evaluation import CrossEncoderCorrelationEvaluator\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from itertools import combinations\n",
    "import random\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artworks_ds = load_dataset(\"anna-bozhenko/artworks\", split=\"train\")\n",
    "artworks_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text_list, tokenizer, model, device=\"cuda\"):\n",
    "    encoded_input = tokenizer(\n",
    "        text_list, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "    model_output = model(**encoded_input)\n",
    "    return mean_pooling(model_output, encoded_input['attention_mask'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedd with sentence-transformers/multi-qa-MiniLM-L6-cos-v1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'sentence-transformers/multi-qa-mpnet-base-cos-v1'\n",
    "model_checkpoint = 'sentence-transformers/multi-qa-MiniLM-L6-cos-v1'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "bi_encoder = AutoModel.from_pretrained(model_checkpoint).cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artworks_ds = artworks_ds.map(\n",
    "    lambda batch: {\"embeddings\": [get_embeddings(x, tokenizer, bi_encoder) for x in batch[\"full_info\"]]},\n",
    "    batched = True,\n",
    "    batch_size = 10\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform bi-encoder augmentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset clustering most relative `full_info`s descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chicago_ds = load_from_disk(\"/content/drive/MyDrive/artistic_styles/paintings/chicago_ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paintings_drawings_chicago_ds = chicago_ds.map(lambda x, i: {\"is_paint_draw\": i if sum(\n",
    "    [clasf in ' '.join(x['classification']).lower()\n",
    "     for clasf in [\"drawing\", \"painting\"]]\n",
    "    ) > 0 else -1},\n",
    "                                               with_indices=True\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "painting_drawings_idxs = paintings_drawings_chicago_ds.filter(lambda x: x['is_paint_draw'] >= 0)['is_paint_draw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find range of indices of paper and canvases artworks, from Chicago Institute of Arts \n",
    "chicago_ds_len = len(chicago_ds)\n",
    "louvre_paintings = len(artworks_ds) - chicago_ds_len\n",
    "chicago_draw_paint_idxs_within_artworks_ds = [i+louvre_paintings for i in painting_drawings_idxs]\n",
    "embedding_idxs = list(range(louvre_paintings)) + chicago_draw_paint_idxs_within_artworks_ds\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, extract from the collective `artworks` necessary \"Chicago\" drawings and paintins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset for creating labels\n",
    "ds0 = artworks_ds.select(embedding_idxs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform dimensions reduction [paper](https://arxiv.org/pdf/1708.03629)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = len(ds0[0][\"embeddings\"])\n",
    "n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = ds0[\"embeddings\"]\n",
    "pca = PCA(n_components=n_components)\n",
    "pca.fit(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise explained variance of clusters' info\n",
    "explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "plt.plot(range(1, 385), explained_variance)\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Let**'s choose 150 PCs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# perform dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 150 # PCs, for PCA\n",
    "D = 3 # dimension to reduce (post-preprocessing )\n",
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(X: np.ndarray, d: int) -> np.ndarray:\n",
    "  \"\"\"PPA: Subtract mean and remove top-d components via PCA projection.\"\"\"\n",
    "  X_centered = X - X.mean(axis=0)\n",
    "\n",
    "  pca = PCA(n_components=D)\n",
    "  pca.fit(X_centered)\n",
    "  U = pca.components_\n",
    "\n",
    "  for u in U:\n",
    "    X_centered -= X_centered @ u[:, None] * u[None, :]\n",
    "\n",
    "  return X_centered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_embeddings(X: np.ndarray, n_components: int, d: int = 1, plot_variance: bool = True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    X - array with initial dimensions\n",
    "    n_components - number of PCs to retain\n",
    "    d - nember of PCs to remove (these PCs bring \"noisy\" data)\n",
    "    \"\"\"\n",
    "    # Step 1: PPA on original embeddings\n",
    "    X_purified = post_process(X, d)\n",
    "\n",
    "    # Step 2: PCA dimensionality reduction\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_reduced = pca.fit_transform(X_purified)\n",
    "\n",
    "    if plot_variance:\n",
    "        explained = np.cumsum(pca.explained_variance_ratio_) * 100\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(range(1, n_components + 1), explained, marker='o')\n",
    "        plt.xlabel('Number of Components')\n",
    "        plt.ylabel('Cumulative Explained Variance (%)')\n",
    "        plt.title('PCA Explained Variance (After First PPA)')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        for i in range(9, n_components+1, 10):\n",
    "          print(f\"{i+1} componets: {explained[i]:.2f}%\")\n",
    "\n",
    "\n",
    "    # Step 3: PPA on reduced embeddings\n",
    "    X_final = post_process(X_reduced, d)\n",
    "\n",
    "    return X_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_embeddings = reduce_embeddings(X=embeddings,\n",
    "                                       n_components=N,\n",
    "                                       d=D,\n",
    "                                       plot_variance=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusterize reduced dimensions embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_clusters = 1000\n",
    "kmeans = MiniBatchKMeans(n_clusters=N_clusters, batch_size=512)\n",
    "labels = kmeans.fit_predict(reduced_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds0 = ds0.add_column(\"label\", labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's form positive and negative pairs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pairs(dataset, cluster_assignments, max_pos_per_cluster=100, num_negatives=100000):\n",
    "    \"\"\"\n",
    "    dataset: HuggingFace Dataset\n",
    "    cluster_assignments: List[int],\n",
    "    returns positive (from one cluster) and negative(from different clusters) pairs\"\"\"\n",
    "    cluster_to_indices = defaultdict(list)\n",
    "    for idx, cluster_id in enumerate(cluster_assignments):\n",
    "        cluster_to_indices[cluster_id].append(idx)\n",
    "\n",
    "    positive_pairs = []\n",
    "    for cluster_id, indices in cluster_to_indices.items():\n",
    "        if len(indices) < 2:\n",
    "            continue\n",
    "        comb = list(combinations(indices, 2))\n",
    "        random.shuffle(comb)\n",
    "        for i, j in comb[:max_pos_per_cluster]:\n",
    "            positive_pairs.append((dataset[i]['full_info'], dataset[j]['full_info'], 1.0))\n",
    "\n",
    "    print(f\"Generated {len(positive_pairs)} positive pairs\")\n",
    "\n",
    "    # Negative pairs\n",
    "    all_indices = list(range(len(dataset)))\n",
    "    negative_pairs = []\n",
    "    while len(negative_pairs) < num_negatives:\n",
    "        i, j = random.sample(all_indices, 2)\n",
    "        if cluster_assignments[i] != cluster_assignments[j]:\n",
    "            negative_pairs.append((dataset[i]['full_info'], dataset[j]['full_info'], 0.0))\n",
    "\n",
    "    print(f\"Generated {len(negative_pairs)} negative pairs\")\n",
    "\n",
    "    pairs = {\n",
    "        \"positive\": positive_pairs,\n",
    "        \"negative\": negative_pairs\n",
    "    }\n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = generate_pairs(ds0, cluster_assignments=labels,\n",
    "                       max_pos_per_cluster=4,\n",
    "                       num_negatives=5_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_text(text, max_tokens=512):\n",
    "    return \" \".join(text.split()[:max_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = pairs.get(\"positive\") + pairs.get(\"negative\")\n",
    "\n",
    "random.shuffle(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-encoder expects a tokenised vector size <= 512, so roughly truncate texts\n",
    "for i in range(len(train_samples)):\n",
    "  sen_1, sen_2, label = train_samples[i]\n",
    "  train_samples[i] = (truncate_text(sen_1, 400),\n",
    "                      truncate_text(sen_2, 400), label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = []\n",
    "\n",
    "for sent1, sent2, label in train_samples:\n",
    "  train_inputs.append(InputExample(texts=[sent1, sent2], label=label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(train_inputs, test_size=0.1)\n",
    "train_dataloader = DataLoader(train_data, shuffle=True, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = CrossEncoderCorrelationEvaluator.from_input_examples(val_data, name=\"dev-set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 'cross-encoder/ms-marco-MiniLM-L-6-v2'\n",
    "cross_encoder = CrossEncoder(model_checkpoint, num_labels=1).cuda()\n",
    "num_epochs = 3\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)\n",
    "out_cross_encoder_path = \"/content/drive/MyDrive/artistic_styles/paintings/augmenting_model/cross-encoder-artworks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_encoder.fit(\n",
    "    train_dataloader=train_dataloader,\n",
    "    evaluator=evaluator,\n",
    "    epochs=num_epochs,\n",
    "    evaluation_steps=250,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=\"/content/drive/MyDrive/artistic_styles/paintings/augmenting_model/cross-encoder-artworks\"\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling silver the dataset to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_pairs = generate_pairs(ds0, cluster_assignments=labels,\n",
    "                       max_pos_per_cluster=10,\n",
    "                       num_negatives=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_pairs = random.sample(silver_pairs[\"positive\"], 2000)\n",
    "neg_pairs = random.sample(silver_pairs[\"negative\"], 2000)\n",
    "\n",
    "silver_pairs = pos_pairs + neg_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_inputs = [[sen1, sen2] for sen1, sen2, score in silver_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_encoder.predict(silver_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.7\n",
    "\n",
    "silver_data = [\n",
    "    InputExample(texts=[pair[0], pair[1]], label=float(score > threshold))\n",
    "    for pair, score in zip(silver_inputs, scores)\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training bi-encoder on silver data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(silver_data, shuffle=True, batch_size=16)  # або 32, залежно від GPU\n",
    "checkpoint = \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\"\n",
    "bi_encoder = SentenceTransformer(checkpoint).cuda()\n",
    "train_loss = losses.CosineSimilarityLoss(model=bi_encoder)\n",
    "num_epochs = 3  # або 2-3, залежно від розміру silver dataset\n",
    "warmup_steps = int(len(train_dataloader) * num_epochs * 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_encoder.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=num_epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=\"/content/drive/MyDrive/artistic_styles/paintings/augmenting_model/bi-encoder-art-silver\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git config --global user.email \"ms.anna.bozhenko.03@gmail.com\"\n",
    "# !git config --global user.name \"Anna Bozhenko\"\n",
    "\n",
    "notebook_login()\n",
    "bi_encoder.push_to_hub(\"anna-bozhenko/artworks-search-MiniLM-L6-cos-v1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
